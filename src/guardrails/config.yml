# The main LLM is provided programmatically in your Python code,
# so it is not specified here.
colang_version: "2.x"
# This section tells the guardrails engine which flows to execute.
models:
  - type: main
    engine: custom_llm 